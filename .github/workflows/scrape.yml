name: Scrape and Save Page

on:
  workflow_dispatch:
    inputs:
      target_url:
        description: 'スクレイピング対象のURL'
        required: true
        type: string

jobs:
  scrape-page:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: リポジトリをチェックアウト
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # 完全な履歴を取得

      - name: Gitの設定
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: Pythonをセットアップ
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            **/requirements.txt
            **/requirements-dev.txt

      - name: システム情報表示
        run: |
          python -V
          pip -V
          uname -a
          free -h
          df -h

      - name: システム依存関係のインストール
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgbm-dev \
            libatk1.0-0 \
            libatk-bridge2.0-0 \
            libcups2 \
            libdrm2 \
            libxkbcommon0 \
            libxcomposite1 \
            libxdamage1 \
            libxfixes3 \
            libxrandr2 \
            libgbm1 \
            libasound2t64 \
            libpango-1.0-0 \
            libpangocairo-1.0-0 \
            libnspr4 \
            libnss3 \
            libx11-xcb1 \
            libfontconfig1 \
            libfreetype6

      - name: Python依存関係のインストール
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4 asyncio urllib3 requests

      - name: Playwrightとブラウザのインストール
        run: |
          playwright install
          playwright install-deps firefox
          playwright install firefox

      - name: 出力ディレクトリの準備
        run: |
          mkdir -p sites
          touch url_patterns.json
          [ -s url_patterns.json ] || echo "{}" > url_patterns.json

      - name: ページのスクレイピング
        env:
          TARGET_URL: ${{ github.event.inputs.target_url }}
          PYTHONUNBUFFERED: "1"
          DEBUG: "pw:api"
        run: |
          echo "スクレイピングを開始: $TARGET_URL"
          python scraper.py "$TARGET_URL"

      - name: スクレイピング結果の確認
        run: |
          if [ -d "sites" ]; then
            echo "保存されたファイル:"
            find sites -type f -name "*.html" -exec ls -lh {} \;
          else
            echo "sitesディレクトリが見つかりません"
            exit 1
          fi

      - name: 変更の確認とコミット
        run: |
          git add -f url_patterns.json sites/
          if git diff --cached --quiet; then
            echo "コミットする変更はありません"
          else
            echo "変更をコミットします"
            git commit -m "Scrape: ${{ github.event.inputs.target_url }} ($(date -u '+%Y-%m-%d %H:%M:%S UTC')) [skip ci]"
            git push origin HEAD:main
          fi
