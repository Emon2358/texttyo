name: Web Scraper

on:
  workflow_dispatch:
    inputs:
      urls:
        description: 'URLs to scrape (comma-separated)'
        required: true
        type: string
      output_branch:
        description: 'Branch to save scraped content'
        required: false
        default: 'scraped-content'
        type: string

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Set up Chrome
        uses: browser-actions/setup-chrome@v1
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp beautifulsoup4 selenium webdriver-manager
      
      - name: Create output directory
        run: mkdir -p pages
      
      - name: Run Web Scraper
        env:
          URLS: ${{ github.event.inputs.urls }}
        run: |
          # Split comma-separated URLs
          IFS=',' read -ra URL_ARRAY <<< "$URLS"
          
          # Run scraper with URLs
          python scraper.py "${URL_ARRAY[@]}"
      
      - name: Check scraped content
        run: |
          echo "Scraped files:"
          ls -R pages/
      
      - name: Create scraped content branch
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          
          # Create or switch to the output branch
          git checkout -B ${{ github.event.inputs.output_branch }}
          
          # Add scraped content
          git add pages/
          
          # Commit changes
          git commit -m "Scrape web content at $(date)" || echo "No changes to commit"
          
          # Push to remote branch
          git push -f origin ${{ github.event.inputs.output_branch }}
      
      - name: Upload scraped content
        uses: actions/upload-artifact@v3
        with:
          name: scraped-pages
          path: pages/
          retention-days: 7
