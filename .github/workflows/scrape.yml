name: Scrape and Save Page
on:
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target URL to scrape'
        required: true
        type: string

jobs:
  scrape-page:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp beautifulsoup4
      
      - name: Create initial url_patterns.json if not exists
        run: |
          if [ ! -f url_patterns.json ]; then
            echo "{}" > url_patterns.json
          fi
      
      - name: Scrape and save page
        run: |
          python scraper.py "${{ github.event.inputs.target_url }}"
      
      - name: Commit and push changes
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          
          # Create pages directory if it doesn't exist
          mkdir -p pages
          
          # Add only existing files
          git add -f url_patterns.json
          git add -f pages/
          
          # Check if there are any changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update scraped page from ${{ github.event.inputs.target_url }}"
            git push
          fi
